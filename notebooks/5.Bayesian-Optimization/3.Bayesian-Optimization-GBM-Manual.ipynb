{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization with Scikit-Optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use **Bayesian Optimization** to select the best **hyperparameters** for a Gradient Boosting Classifier, using the open source Python package Scikit-Optimize.\n",
    "\n",
    "We will do the search manually, defining the objective function (hyperparameter response function ) and using the Gaussian Process minimizer class from Scikit-optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important\n",
    "Remember that we use **Bayesian Optimization** when we are looking to optimize functions that are costly, like those derived from neuronal networks. For a Gradient Boosting Machine trained on little data like the one in this notebook, we would probably make a better search if we carried out a Random Search.\n",
    "\n",
    "An example from scikit-optimize to optimize a regression can be found here\n",
    "\n",
    "#### Hyperparameter Tunning Procedure\n",
    "To tune the hyper-parameters of our model we need to:\n",
    "\n",
    "* define a model\n",
    "* decide which parameters to optimize\n",
    "* define the objective function we want to minimize.\n",
    "\n",
    "#### NOTE\n",
    "Scikit-Optimize will always **minimize** the objective function, so if we want to maximize a function, for example the roc-auc, we need to **negate** the metric. Thus, instead of maximizing the roc-auc, we minimize the -roc-auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8   \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9   ...     20     21      22      23      24      25      26      27  \\\n",
       "0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       28       29  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "breast_cancer_X, breast_cancer_y = load_breast_cancer(return_X_y=True)\n",
    "X = pd.DataFrame(breast_cancer_X)\n",
    "y = pd.Series(breast_cancer_y).map({0:1, 1:0})\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.627417\n",
       "1    0.372583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target:\n",
    "# percentage of benign (0) and malign tumors (1)\n",
    "\n",
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Hyperparameter Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-optimize provides an utility function to create the range of values to examine for each hyperparameters. More details in skopt.Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Integer(low=10, high=120, prior='uniform', transform='identity')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Integer, we create a space of integers, sampled uniformly\n",
    "# between the minimum and maximum indicated values\n",
    "\n",
    "Integer(10, 120, name=\"n_estimators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Real(low=0, high=0.999, prior='uniform', transform='identity')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Real, we create a space of real values, sampled uniformly\n",
    "# between the minimum and maximum indicated values\n",
    "\n",
    "Real(0, 0.999, name=\"min_samples_split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical(categories=('deviance', 'exponential'), prior=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Categorical, we create a space of categories\n",
    "\n",
    "Categorical(['deviance', 'exponential'], name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the hyperparameter space\n",
    "\n",
    "param_grid = [\n",
    "    Integer(10, 120, name=\"n_estimators\"),\n",
    "    Real(0.001, 0.999, name=\"min_samples_split\"),\n",
    "    Integer(1, 5, name=\"max_depth\"),\n",
    "    Categorical(['deviance', 'exponential'], name=\"loss\"),\n",
    "]\n",
    "\n",
    "# Scikit-optimize parameter grid is a list\n",
    "type(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the gradient boosting classifier\n",
    "\n",
    "gbm = GradientBoostingClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the hyperparameter response space, the function we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We design a function to maximize the accuracy, of a GBM,\n",
    "# with cross-validation\n",
    "\n",
    "# the decorator allows our objective function to receive the parameters as\n",
    "# keyword arguments. This is a requirement of Scikit-Optimize.\n",
    "@use_named_args(param_grid)\n",
    "def objective(**params):\n",
    "    \n",
    "    # model with new parameters\n",
    "    gbm.set_params(**params)\n",
    "\n",
    "    # optimization function (hyperparam response function)\n",
    "    value = np.mean(\n",
    "        cross_val_score(\n",
    "            gbm, \n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=3,\n",
    "            n_jobs=-4,\n",
    "            scoring='accuracy')\n",
    "    )\n",
    "\n",
    "    # negate because we need to minimize\n",
    "    return -value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready for sequential model-based optimization. Here we use Gaussian process-based Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# gp_minimize performs by default GP Optimization \n",
    "# using a Marten Kernel\n",
    "\n",
    "gp_ = gp_minimize(\n",
    "    objective, # the objective function to minimize\n",
    "    param_grid, # the hyperparameter space\n",
    "    n_initial_points=10, # the number of points to evaluate f(x) to start of\n",
    "    acq_func='EI', # the acquisition function\n",
    "    n_calls=50, # the number of subsequent evaluations of f(x)\n",
    "    random_state=0, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best score=-0.9698'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function value at the minimum.\n",
    "# note that it is the negative of the accuracy\n",
    "\n",
    "\"Best score=%.4f\" % gp_.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "=========================\n",
      "- n_estimators=120\n",
      "- min_samples_split=0.914098\n",
      "- max_depth=4\n",
      "- loss = deviance\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Best parameters:\n",
    "=========================\n",
    "- n_estimators=%d\n",
    "- min_samples_split=%.6f\n",
    "- max_depth=%d\n",
    "- loss = %s\"\"\" % (gp_.x[0], \n",
    "                gp_.x[1],\n",
    "                gp_.x[2],\n",
    "                gp_.x[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate convergence of the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Convergence plot'}, xlabel='Number of calls $n$', ylabel='$\\\\min f(x)$ after $n$ calls'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(gp_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with around 20 iterations, the procedure already found the minimum of the hyperparamter response function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('hyperparameter_optimization_for_machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f33e3a0ecdca2dfa9e05d6e5730c703bfe1984a713822542070e9abfcf88fe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
