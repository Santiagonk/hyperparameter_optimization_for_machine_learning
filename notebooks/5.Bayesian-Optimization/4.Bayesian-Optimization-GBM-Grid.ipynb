{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimisation with Scikit-Optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use **Bayesian Optimization** to select the best **hyperparameters** for a Gradient Boosting Regressor, using the open source Python package Scikit-Optimize.\n",
    "\n",
    "Scikit-Optimize offers an interface that allows us to do the Optimization in a similar way to the GridSearchCV or RandomizedSearchCV from Scikit-learn, through the class BayesSearchCV\n",
    "\n",
    "In this notebook, we will see how to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important\n",
    "Remember that we use **Bayesian Optimization** when we are looking to optimize functions that are costly, like those derived from neuronal networks. For a Gradient Boosting Machine trained on little data like the one in this notebook, we would probably make a better search if we carried out a Random Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tunning Procedure\n",
    "To tune the hyper-parameters of our model we need to:\n",
    "\n",
    "* define a model\n",
    "* decide which parameters to optimize\n",
    "* define the objective function we want to minimize.\n",
    "\n",
    "#### NOTE\n",
    "Scikit-Optimize will always minimize the objective function, so if we want to maximize a function, for example the roc-auc, we need to negate the metric. Thus, instead of maximizing the roc-auc, we minimize the -roc-auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# note that we only need to import the wrapper\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4      5     6       7    8      9     10  \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "\n",
       "       11    12  \n",
       "0  396.90  4.98  \n",
       "1  396.90  9.14  \n",
       "2  392.83  4.03  \n",
       "3  394.63  2.94  \n",
       "4  396.90  5.33  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "boston_X, boston_y = load_boston(return_X_y=True)\n",
    "X = pd.DataFrame(boston_X)\n",
    "y = pd.Series(boston_y)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.hist(bins=50)\n",
    "plt.title(\"House median price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((354, 13), (152, 13))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model and Hyperparameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "\n",
    "gbm = GradientBoostingRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter space\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': (10, 120), \n",
    "    'min_samples_split': (0.001, 0.99, 'log-uniform'),\n",
    "    'max_depth': (1, 8),\n",
    "    'loss': ['ls', 'lad', 'huber'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At the moment of creating this notebook, the BayesSearchCV is not\n",
    "# compatible with sklearn version 0.24, because in this version the \n",
    "# param iid was deprecated from sklearn, and not yet from scikit-optimize\n",
    "\n",
    "# make sure you have version 0.23 of sklearn to run this notebook\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the notebook is very similar to that of RandomizedSearchCV, because the BayesSearchCV makes sure to bring forward all of Scikit-learn functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/santiago/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:301: FutureWarning: The loss 'lad' was deprecated in v1.0 and will be removed in version 1.2. Use 'absolute_error' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=3, estimator=GradientBoostingRegressor(random_state=0),\n",
       "              n_jobs=4, random_state=10, scoring=&#x27;neg_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;loss&#x27;: [&#x27;ls&#x27;, &#x27;lad&#x27;, &#x27;huber&#x27;],\n",
       "                             &#x27;max_depth&#x27;: (1, 8),\n",
       "                             &#x27;min_samples_split&#x27;: (0.001, 0.99, &#x27;log-uniform&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: (10, 120)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=3, estimator=GradientBoostingRegressor(random_state=0),\n",
       "              n_jobs=4, random_state=10, scoring=&#x27;neg_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;loss&#x27;: [&#x27;ls&#x27;, &#x27;lad&#x27;, &#x27;huber&#x27;],\n",
       "                             &#x27;max_depth&#x27;: (1, 8),\n",
       "                             &#x27;min_samples_split&#x27;: (0.001, 0.99, &#x27;log-uniform&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: (10, 120)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=3, estimator=GradientBoostingRegressor(random_state=0),\n",
       "              n_jobs=4, random_state=10, scoring='neg_mean_squared_error',\n",
       "              search_spaces={'loss': ['ls', 'lad', 'huber'],\n",
       "                             'max_depth': (1, 8),\n",
       "                             'min_samples_split': (0.001, 0.99, 'log-uniform'),\n",
       "                             'n_estimators': (10, 120)})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up the search\n",
    "search = BayesSearchCV(\n",
    "    estimator=gbm,\n",
    "    search_spaces=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    n_iter=50,\n",
    "    random_state=10,\n",
    "    n_jobs=4,\n",
    "    refit=True)\n",
    "\n",
    "# find best hyperparameters\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('loss', 'huber'),\n",
       "             ('max_depth', 3),\n",
       "             ('min_samples_split', 0.011493762380048851),\n",
       "             ('n_estimators', 74)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the best hyperparameters are stored in an attribute\n",
    "\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.555088456356303"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the best score\n",
    "\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.018659</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>huber</td>\n",
       "      <td>3</td>\n",
       "      <td>0.044228</td>\n",
       "      <td>80</td>\n",
       "      <td>{'loss': 'huber', 'max_depth': 3, 'min_samples...</td>\n",
       "      <td>-10.558287</td>\n",
       "      <td>-16.394026</td>\n",
       "      <td>-13.460963</td>\n",
       "      <td>-13.471092</td>\n",
       "      <td>2.382441</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068624</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>ls</td>\n",
       "      <td>2</td>\n",
       "      <td>0.308189</td>\n",
       "      <td>76</td>\n",
       "      <td>{'loss': 'ls', 'max_depth': 2, 'min_samples_sp...</td>\n",
       "      <td>-11.740731</td>\n",
       "      <td>-18.260354</td>\n",
       "      <td>-14.708708</td>\n",
       "      <td>-14.903264</td>\n",
       "      <td>2.665178</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.166714</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>lad</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>48</td>\n",
       "      <td>{'loss': 'lad', 'max_depth': 3, 'min_samples_s...</td>\n",
       "      <td>-9.253265</td>\n",
       "      <td>-17.728812</td>\n",
       "      <td>-18.140297</td>\n",
       "      <td>-15.040791</td>\n",
       "      <td>4.095845</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127385</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>ls</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>90</td>\n",
       "      <td>{'loss': 'ls', 'max_depth': 5, 'min_samples_sp...</td>\n",
       "      <td>-17.641456</td>\n",
       "      <td>-26.860518</td>\n",
       "      <td>-9.886990</td>\n",
       "      <td>-18.129655</td>\n",
       "      <td>6.938007</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070725</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>ls</td>\n",
       "      <td>4</td>\n",
       "      <td>0.054687</td>\n",
       "      <td>54</td>\n",
       "      <td>{'loss': 'ls', 'max_depth': 4, 'min_samples_sp...</td>\n",
       "      <td>-11.734966</td>\n",
       "      <td>-26.734377</td>\n",
       "      <td>-11.014968</td>\n",
       "      <td>-16.494771</td>\n",
       "      <td>7.246459</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_loss  \\\n",
       "0       0.516908      0.018659         0.002581        0.000525      huber   \n",
       "1       0.068624      0.009148         0.002404        0.000646         ls   \n",
       "2       0.166714      0.012566         0.002432        0.000627        lad   \n",
       "3       0.127385      0.004397         0.004555        0.002957         ls   \n",
       "4       0.070725      0.002778         0.002181        0.000234         ls   \n",
       "\n",
       "  param_max_depth param_min_samples_split param_n_estimators  \\\n",
       "0               3                0.044228                 80   \n",
       "1               2                0.308189                 76   \n",
       "2               3                0.002288                 48   \n",
       "3               5                0.001897                 90   \n",
       "4               4                0.054687                 54   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'loss': 'huber', 'max_depth': 3, 'min_samples...         -10.558287   \n",
       "1  {'loss': 'ls', 'max_depth': 2, 'min_samples_sp...         -11.740731   \n",
       "2  {'loss': 'lad', 'max_depth': 3, 'min_samples_s...          -9.253265   \n",
       "3  {'loss': 'ls', 'max_depth': 5, 'min_samples_sp...         -17.641456   \n",
       "4  {'loss': 'ls', 'max_depth': 4, 'min_samples_sp...         -11.734966   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0         -16.394026         -13.460963       -13.471092        2.382441   \n",
       "1         -18.260354         -14.708708       -14.903264        2.665178   \n",
       "2         -17.728812         -18.140297       -15.040791        4.095845   \n",
       "3         -26.860518          -9.886990       -18.129655        6.938007   \n",
       "4         -26.734377         -11.014968       -16.494771        7.246459   \n",
       "\n",
       "   rank_test_score  \n",
       "0               35  \n",
       "1               44  \n",
       "2               45  \n",
       "3               49  \n",
       "4               48  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we also find the data for all models evaluated\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "print(results.shape)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Hyperparameter combinations')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can order the different models based on their performance\n",
    "results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
    "\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# plot model performance and error\n",
    "\n",
    "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
    "\n",
    "plt.ylabel('Mean test score')\n",
    "plt.xlabel('Hyperparameter combinations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE:  2.077241345322855\n",
      "Test MSE:  15.810352809406744\n"
     ]
    }
   ],
   "source": [
    "X_train_preds = search.predict(X_train)\n",
    "X_test_preds = search.predict(X_test)\n",
    "\n",
    "print('Train MSE: ', mean_squared_error(y_train, X_train_preds))\n",
    "print('Test MSE: ', mean_squared_error(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('hyperparameter_optimization_for_machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f33e3a0ecdca2dfa9e05d6e5730c703bfe1984a713822542070e9abfcf88fe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
