{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization of CNN with Scikit-Optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use **Bayesian Optimization** to select the best **hyperparameters** for a CNN that recognizes digits in images, using the MNIST dataset and the open source Python package Scikit-Optimize.\n",
    "\n",
    "The MNIST dataset is availale in Kaggle.\n",
    "\n",
    "#### Download dataset\n",
    "* Navigate to the MNIST website in Kaggle\n",
    "* Download the train.csv file\n",
    "* Unzip and copy the train.csv file to where you see the SAVE_DATASETS-HERE.txt file\n",
    "* Rename to mnist.csv\n",
    "\n",
    "**Remember that you need to be logged in to be able to download the dataset**\n",
    "\n",
    "#### Notebook content\n",
    "* Data Preparation\n",
    "* Set up a simple CNN\n",
    "* Set up the hyperparameter search shape\n",
    "* Set up the objective function\n",
    "* Perform Bayesian Optimization\n",
    "* Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains information about images, each image is a hand-written digit. The aim is to have the computer predict which digit was written by the person, automatically, by \"looking\" at the image.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width (28 x 28), making a total of 784 pixels. Each pixel value is an integer between 0 and 255, indicating the darkness in a gray-scale of that pixel.\n",
    "\n",
    "The data is stored in a dataframe where each each pixel is a column (so it is flattened and not in the 28 x 28 format).\n",
    "\n",
    "The data set the has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "data = pd.read_csv(\"../../data/processed/mnist.csv\")\n",
    "\n",
    "# first column is the target, the rest of the columns\n",
    "# are the pixels of the image\n",
    "\n",
    "# each row is 1 image\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37800, 784), (4200, 784))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['label'], axis=1), # the images\n",
    "    data['label'], # the target\n",
    "    test_size = 0.1,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of images')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of images for each digit\n",
    "\n",
    "g = sns.countplot(x=y_train)\n",
    "plt.xlabel('Digits')\n",
    "plt.ylabel('Number of images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are roughly the same amount of images for each of the 10 digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image re-scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-scale data for the CNN, between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-scale the data\n",
    "\n",
    "# 255 is the maximum value a pixel can take\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images were stored in a pandas dataframe as 1-D vectors of 784 values. For a CNN with Keras, we need tensors with the following dimensions: width x height x channel.\n",
    "\n",
    "Thus, we reshape all data to 28 x 2 8 x 1, 3-D matrices.\n",
    "\n",
    "The 3rd dimension corresponds to the channel. RGB images have 3 channels. MNIST images are in gray-scale, thus they have only one channel in the 3rd dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions:\n",
    "# height: 28px X width: 28px X channel: 1 \n",
    "\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_test = X_test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 7, 4, 3, 5, 9, 6, 8, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target is 1 variable with the 9 different digits\n",
    "# as values\n",
    "\n",
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Keras, we need to create 10 dummy variables,\n",
    "# one for each digit\n",
    "\n",
    "# Encode labels to one hot vectors (ex : digit 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)\n",
    "\n",
    "# the new target\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some image examples \n",
    "\n",
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some image examples \n",
    "\n",
    "g = plt.imshow(X_train[10][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a CNN, with 2 Convolutional layers followed by Pooling, and varying number of fully-connected Dense layers.\n",
    "\n",
    "In fact, the number of fully-connected Dense layers and the number of Neurons in each one of the Dense layers, are some of the hyperparameters we want to optimize.\n",
    "\n",
    "We could also optimize the number of Convolutional layers. But we will keep that for later, and here we keep it a bit simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the CNN\n",
    "\n",
    "def create_cnn(\n",
    "    learning_rate,\n",
    "    num_dense_layers,\n",
    "    num_dense_nodes,\n",
    "    activation,\n",
    "):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Start construction of a Keras Sequential model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # First convolutional layer.\n",
    "    # There are many hyper-parameters in this layer\n",
    "    # For this demo, we will optimize the activation function only.\n",
    "    model.add(Conv2D(kernel_size=5, strides=1, filters=16, padding='same',\n",
    "                     activation=activation, name='layer_conv1'))\n",
    "    model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "    # Second convolutional layer.\n",
    "    # Again, we will only optimize the activation function.\n",
    "    model.add(Conv2D(kernel_size=5, strides=1, filters=36, padding='same',\n",
    "                     activation=activation, name='layer_conv2'))\n",
    "    model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "    # Flatten the 4-rank output of the convolutional layers\n",
    "    # to 2-rank that can be input to a fully-connected Dense layer.\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Add fully-connected Dense layers.\n",
    "    # The number of layers is a hyper-parameter we want to optimize.\n",
    "    # We add the different number of layers in the following loop:\n",
    "    \n",
    "    for i in range(num_dense_layers):\n",
    "        \n",
    "        # Add the dense fully-connected layer to the model.\n",
    "        # This has two hyper-parameters we want to optimize:\n",
    "        # The number of nodes (neurons) and the activation function.\n",
    "        model.add(Dense(num_dense_nodes,\n",
    "                        activation=activation,\n",
    "                        ))\n",
    "\n",
    "    # Last fully-connected dense layer with softmax-activation\n",
    "    # for use in classification.\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Use the Adam method for training the network.\n",
    "    # We want to find the best learning-rate for the Adam method.\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "    # In Keras we need to compile the model so it can be trained.\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Hyperparameter Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-optimize provides an utility function to create the range of values to examine for each hyperparameters. More details in skopt.Space\n",
    "\n",
    "We want to find the following hyper-parameters:\n",
    "\n",
    "* The learning rate of the optimizer.\n",
    "* The number of fully-connected Dense layers.\n",
    "* The number of nodes (neurons) for each of the dense layers.\n",
    "* Whether to use 'sigmoid' or 'relu' activation in all the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_learning_rate = Real(\n",
    "    low=1e-6, high=1e-2, prior='log-uniform', name='learning_rate',\n",
    ")\n",
    "\n",
    "dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
    "\n",
    "dim_num_dense_nodes = Integer(low=5, high=512, name='num_dense_nodes')\n",
    "\n",
    "\n",
    "dim_activation = Categorical(\n",
    "    categories=['relu', 'sigmoid'], name='activation',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the hyperparameter space grid\n",
    "\n",
    "param_grid = [dim_learning_rate,\n",
    "              dim_num_dense_layers,\n",
    "              dim_num_dense_nodes,\n",
    "              dim_activation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will save the model with this name\n",
    "path_best_model = 'cnn_model.h5'\n",
    "\n",
    "# starting point for the optimization\n",
    "best_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(param_grid)\n",
    "def objective(\n",
    "    learning_rate,\n",
    "    num_dense_layers,\n",
    "    num_dense_nodes,\n",
    "    activation,\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_layers:', num_dense_layers)\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('activation:', activation)\n",
    "    print()\n",
    "    \n",
    "    # Create the neural network with the hyper-parameters.\n",
    "    # We call the function we created previously.\n",
    "    model = create_cnn(learning_rate=learning_rate,\n",
    "                       num_dense_layers=num_dense_layers,\n",
    "                       num_dense_nodes=num_dense_nodes,\n",
    "                       activation=activation)\n",
    "\n",
    "   \n",
    "    # Set a learning rate annealer\n",
    "    # this reduces the learning rate if learning does not improve\n",
    "    # for a certain number of epochs\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                                patience=2, \n",
    "                                                verbose=1, \n",
    "                                                factor=0.5, \n",
    "                                                min_lr=0.00001)\n",
    "   \n",
    "    # train the model\n",
    "    # we use 3 epochs to be able to run the notebook in a \"reasonable\"\n",
    "    # time. If we increase the epochs, we will have better performance\n",
    "    # this could be another parameter to optimize in fact.\n",
    "    history = model.fit(x=X_train,\n",
    "                        y=y_train,\n",
    "                        epochs=3,\n",
    "                        batch_size=128,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=learning_rate_reduction)\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_accuracy\n",
    "\n",
    "    # If the classification accuracy of the saved model is improved ...\n",
    "    if accuracy > best_accuracy:\n",
    "        # Save the new model to harddisk.\n",
    "        # Training CNNs is costly, so we want to avoid having to re-train\n",
    "        # the network with the best found parameters. We save it instead\n",
    "        # as we search for the best hyperparam space.\n",
    "        model.save(path_best_model)\n",
    "        \n",
    "        # Update the classification accuracy.\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    \n",
    "    # Remember that Scikit-optimize always minimizes the objective\n",
    "    # function, so we need to negate the accuracy (because we want\n",
    "    # the maximum accuracy)\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1.0e-05\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 16\n",
      "activation: relu\n",
      "\n",
      "Epoch 1/3\n",
      "266/266 [==============================] - 15s 56ms/step - loss: 2.2850 - accuracy: 0.1394 - val_loss: 2.2473 - val_accuracy: 0.1778 - lr: 1.0000e-05\n",
      "Epoch 2/3\n",
      "266/266 [==============================] - 21s 78ms/step - loss: 2.1868 - accuracy: 0.2359 - val_loss: 2.1179 - val_accuracy: 0.2455 - lr: 1.0000e-05\n",
      "Epoch 3/3\n",
      "266/266 [==============================] - 22s 82ms/step - loss: 2.0205 - accuracy: 0.3494 - val_loss: 1.9149 - val_accuracy: 0.4561 - lr: 1.0000e-05\n",
      "\n",
      "Accuracy: 45.61%\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "`save_model()` using h5 format requires h5py. Could not import h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb Celda 35\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Before we run the hyper-parameter optimization, \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# let's first check that the everything is working\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# by passing some default hyper-parameters.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m default_parameters \u001b[39m=\u001b[39m [\u001b[39m1e-5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m objective(x\u001b[39m=\u001b[39;49mdefault_parameters)\n",
      "File \u001b[0;32m~/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/skopt/utils.py:789\u001b[0m, in \u001b[0;36muse_named_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    786\u001b[0m arg_dict \u001b[39m=\u001b[39m {dim\u001b[39m.\u001b[39mname: value \u001b[39mfor\u001b[39;00m dim, value \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(dimensions, x)}\n\u001b[1;32m    788\u001b[0m \u001b[39m# Call the wrapped objective function with the named arguments.\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m objective_value \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49marg_dict)\n\u001b[1;32m    791\u001b[0m \u001b[39mreturn\u001b[39;00m objective_value\n",
      "\u001b[1;32m/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb Celda 35\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(learning_rate, num_dense_layers, num_dense_nodes, activation)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# If the classification accuracy of the saved model is improved ...\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mif\u001b[39;00m accuracy \u001b[39m>\u001b[39m best_accuracy:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m     \u001b[39m# Save the new model to harddisk.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m     \u001b[39m# Training CNNs is costly, so we want to avoid having to re-train\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m     \u001b[39m# the network with the best found parameters. We save it instead\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m     \u001b[39m# as we search for the best hyperparam space.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m     model\u001b[39m.\u001b[39;49msave(path_best_model)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m     \u001b[39m# Update the classification accuracy.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m     best_accuracy \u001b[39m=\u001b[39m accuracy\n",
      "File \u001b[0;32m~/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/keras/saving/hdf5_format.py:79\u001b[0m, in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m\"\"\"Saves a model to a HDF5 file.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \n\u001b[1;32m     55\u001b[0m \u001b[39mThe saved model contains:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39m    ImportError: if h5py is not available.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m h5py \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`save_model()` using h5 format requires h5py. Could not \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     80\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mimport h5py.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[39m# TODO(psv) Add warning when we save models that contain non-serializable\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m# entities like metrics added using `add_metric` and losses added using\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m# `add_loss.`\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(model\u001b[39m.\u001b[39mweights) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(model\u001b[39m.\u001b[39m_undeduplicated_weights):\n",
      "\u001b[0;31mImportError\u001b[0m: `save_model()` using h5 format requires h5py. Could not import h5py."
     ]
    }
   ],
   "source": [
    "# Before we run the hyper-parameter optimization, \n",
    "# let's first check that the everything is working\n",
    "# by passing some default hyper-parameters.\n",
    "default_parameters = [1e-5, 1, 16, 'relu']\n",
    "\n",
    "objective(x=default_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained a mediocre accuracy, but all our code is working. So let's get started with the Optimization now!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gp_minimize performs by default GP Optimization \n",
    "# using a Marten Kernel\n",
    "\n",
    "gp_ = gp_minimize(\n",
    "    objective, # the objective function to minimize\n",
    "    param_grid, # the hyperparameter space\n",
    "    x0=default_parameters, # the initial parameters to test\n",
    "    acq_func='EI', # the acquisition function\n",
    "    n_calls=30, # the number of subsequent evaluations of f(x)\n",
    "    random_state=0, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function value at the minimum.\n",
    "# note that it is the negative of the accuracy\n",
    "\n",
    "\"Best score=%.4f\" % gp_.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_.space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Best parameters:\n",
    "=========================\n",
    "- learning rate=%.6f\n",
    "- num_dense_layers=%d\n",
    "- num_nodes=%d\n",
    "- activation = %s\"\"\" % (gp_.x[0], \n",
    "                gp_.x[1],\n",
    "                gp_.x[2],\n",
    "                gp_.x[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence(gp_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partially dependency plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_names = ['learning_rate', 'num_dense_nodes', 'num_dense_layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gp_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb Celda 47\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m plot_objective(result\u001b[39m=\u001b[39mgp_, plot_dims\u001b[39m=\u001b[39mdim_names)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gp_' is not defined"
     ]
    }
   ],
   "source": [
    "plot_objective(result=gp_, plot_dims=dim_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evaluations(result=gp_, plot_dims=dim_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at cnn_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb Celda 51\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#Y100sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load best model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/ACER/Documents/Udemy/Hyperparameter_Optimization_for_Machine_Learning/hyperparameter_optimization_for_machine_learning/notebooks/5.Bayesian-Optimization/7.Bayesian-Optimization-CNN.ipynb#Y100sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(path_best_model)\n",
      "File \u001b[0;32m~/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/hyperparameter_optimization_for_machine_learning/lib/python3.9/site-packages/keras/saving/save.py:209\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    208\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath):\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    210\u001b[0m   \u001b[39mif\u001b[39;00m saving_utils\u001b[39m.\u001b[39mis_hdf5_filepath(filepath) \u001b[39mand\u001b[39;00m h5py \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    212\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mFilepath looks like a hdf5 file but h5py is not available.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    213\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m filepath=\u001b[39m\u001b[39m{\u001b[39;00mfilepath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at cnn_model.h5"
     ]
    }
   ],
   "source": [
    "# load best model\n",
    "\n",
    "model = load_model(path_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions in test set\n",
    "\n",
    "result = model.evaluate(x=X_test,\n",
    "                        y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print evaluation metrics\n",
    "\n",
    "for name, value in zip(model.metrics_names, result):\n",
    "    print(name, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values from the validation dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions classes to one hot vectors \n",
    "y_pred_classes = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "# Convert validation observations to one hot vectors\n",
    "y_true = np.argmax(y_test, axis = 1)\n",
    "\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes) \n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make it more colourful\n",
    "classes = 10\n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(classes)\n",
    "plt.xticks(tick_marks, range(classes), rotation=45)\n",
    "plt.yticks(tick_marks, range(classes))\n",
    "\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j],\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > 100 else \"black\",\n",
    "            )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that our CNN performs very well on all digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('hyperparameter_optimization_for_machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f33e3a0ecdca2dfa9e05d6e5730c703bfe1984a713822542070e9abfcf88fe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
